---
title: Get started
sidebar_position: 2
description: Learn how to configure, deploy, use, and delete a vCluster instance.
---
import Tabs from '@theme/Tabs'
import TabItem from '@theme/TabItem'
import CodeBlock from '@theme/CodeBlock';

import InstallCLIFragment from '@site/docs/_fragments/quickstart/install-cli.mdx'
import DeployVirtualCluster from '@site/docs/_fragments/quickstart/deploy.mdx'
import Cleanup from '@site/docs/_fragments/quickstart/cleanup.mdx'
import Connect from '@site/docs/_fragments/quickstart/connect.mdx'
import DeployChanges from '@site/docs/_fragments/quickstart/deploy-changes.mdx'


## Key concepts
@TODO remove this once the new architecture page is in place. Then add a link in the Before you begin section.

- [**vCluster Control Plane**](/vcluster/architecture/README.mdx): Contains a Kubernetes API server, a controller manager, a data store mount and the Syncer.
- [**Syncing resources**](/vcluster/architecture/README.mdx): vCluster runs your workloads by syncing pods from the virtual cluster to the host cluster.
- [**Pod scheduling**](/vcluster/architecture/README.mdx): By default, vCluster reuses the host cluster scheduler to schedule workloads.
- [**Storage**](/vcluster/architecture/README.mdx): You can use the host's storage classes without the need to create them in the virtual cluster.
- [**Networking**](/vcluster/architecture/README.mdx): vCluster syncs resources such as Service and Ingress resources from the virtual to the host cluster.
- [**Nodes**](/vcluster/architecture/README.mdx): By default, vCluster creates pseudo nodes for every pod `spec.nodeName` in the virtual cluster.

## Before you begin

You have have access to a Kubernetes v1.26+ cluster to use as the host cluster and have installed [kubectl](https://kubernetes.io/docs/tasks/tools/#kubectl). You do not need admin permissions on the host cluster, but you do need to be able to deploy applications to a namespace.

vCluster deployment uses Helm, which the vCluster CLI installs. If you don't want to use the vCluster CLI, install Helm v3+.

Deploying vCluster is a two-step process:

1. [Install the vCluster CLI](#install-the-vcluster-cli).
1. [Deploy vCluster](#deploy-vcluster).

You can then [use your virtual cluster](#use-virtual-cluster) or [explore features](#explore-features).

## Install the vCluster CLI

<InstallCLIFragment/>

## Configure vCluster (optional)

vCluster uses vanilla Kubernetes for the virtual cluster. If you want to change the Kubernetes distribution before you deploy vCluster, create a config file called `vcluster.yaml`. The following example configures Lightweight Kubernetes (K3s).

```yaml
controlPlane:
  distro:
    k3s:
      enabled: true     
```

## Deploy vCluster

<DeployVirtualCluster/>

## Use your virtual cluster

Interacting with a virtual cluster is very similar to using a standard Kubernetes cluster. 

### Connect

<Connect/>

### Deploy resources inside the virtual cluster

To illustrate what happens in the host cluster, create a namespace and deploy NGINX in the virtual cluster.

```bash
kubectl create namespace demo-nginx
kubectl create deployment ngnix-deployment -n demo-nginx --image=nginx -r 2
```

Check that this deployment creates two pods inside the virtual cluster.

```bash 
kubectl get pods -n demo-nginx
```

Note: Most resources inside your virtual cluster only exist in your virtual cluster and not in the host cluster.

To verify this, perform these steps:

1. Disconnect from the current virtual cluster and switch back to the host context.

    ```bash 
    vcluster disconnect
    ```

1. Check namespaces in the host cluster.

   ```bash 
   kubectl get namespaces
   ``` 
   Output is similar to: 
   ```bash
   NAME                 STATUS   AGE
   default              Active   35m
   kube-public          Active   35m
   kube-system          Active   35m
   # highlight-next-line
   team-x               Active   30m
   ```

1. Look for the `nginx-deployment` deployment.

   ```bash 
   kubectl get deployments -n team-x
   ``` 

   Notice that this resource does NOT exist in the host cluster because it normally does not get synced from the virtual to the host cluster since its typically not required to run workloads on the host cluster.

1. Now, look for the NGINX pods.

   ```bash 
   kubectl get pods -n team-x
   ``` 

   Output is similar to:

   ```bash
   coredns-cb5ccc67f-kqwmx-x-kube-system-x-my-vcluster            1/1     Running   0          34m
   my-vcluster-0                                                  1/1     Running   0          34m
   nginx-deployment-6d6565499c-cbv4w-x-demo-nginx-x-my-vcluster   1/1     Running   0          20m
   nginx-deployment-6d6565499c-s7g8z-x-demo-nginx-x-my-vcluster   1/1     Running   0          20m
   ```
   
   You can see from the output that the the two NGINX pods exist in the host cluster. The vCluster `my-cluster-0` pod is the vCluster control plane.

   :::info K8s Resource Renaming
   To prevent collisions, the pod names and their namespaces are rewritten by vCluster during the sync process from the virtual cluster to the host cluster.
   :::


## Explore features

### Sync pods

Enable Pod syncing from the virtual cluster to the host cluster where the workloads actually run. 

1. Add this configuration to your `vcluster.yaml` config file:

   ```YAML
   sync:
     toHost:
       pods:
         enabled: true
   ```

1. Apply `vcluster.yaml`.
   
   <DeployChanges/>

### Expose the vCluster control plane

There are multiple ways of granting access to the vCluster control plane for external applications like kubectl. The following approach uses an Ingress with SSL-passthrough, but you can also do it via Service Account, LoadBalancer service, and NodePort service.

1. Ensure that you have an ingress controller in a healthy state on the host cluster where vCluster is installed. Enable SSL passthrough. TLS termination must happen at the vCluster level and not the ingress controller level.

1. Create and apply an `Ingress` resource on the host cluster. This example shows the configuration for NGINX, so refer to the respective documentation for other ingress controllers.

      ```yaml
      apiVersion: networking.k8s.io/v1
      kind: Ingress
      metadata:
        annotations:
          nginx.ingress.kubernetes.io/backend-protocol: HTTPS
          nginx.ingress.kubernetes.io/ssl-passthrough: "true"
          nginx.ingress.kubernetes.io/ssl-redirect: "true"
        name: vcluster-ingress
        namespace: my-vcluster
      spec:
        ingressClassName: nginx 
        rules:
        - host: my-vcluster.example.com
          http:
            paths:
            - backend:
                service:
                  name: my-vcluster
                  port:
                    number: 443
              path: /
              pathType: ImplementationSpecific
      ```

      ```bash 
         kubectl apply -f ingress.yaml
      ```

1. Modify `vcluster.yaml` to configure the hostname to sign the vCluster proxy certificate for.

      ```yaml
      controlPlane:
        proxy:
          extraSANs: my-vcluster.example.com
      ```

1. Apply `vcluster.yaml`.
   
   <DeployChanges/>

### Show real nodes

By default, vCluster syncs pseudo nodes from the host cluster to the virtual cluster. However, deploying a vCluster instance via the CLI on a local Kubernetes cluster automatically enables real node syncing, so you would not see a difference in this context.

Pseudo nodes only have real values for the CPU, architecture, and operating system, while everything else is randomly generated. Therefore, for use cases requiring real node information, you can opt to sync the real nodes into the virtual cluster.

1. Modify `vcluster.yaml`.

    ```yaml
    sync:
      fromHost:
        nodes:
          enabled: true
    ```

1. Apply `vcluster.yaml`.

      <DeployChanges/>

### Sync ingress from host to virtual

If you want to use an ingress controller from the host cluster inside your virtual cluster, enable `IngressClass` syncing from host to virtual cluster.

1. Modify `vcluster.yaml`.

    ```yaml
    sync:
      fromHost:
        ingressClasses:
          enabled: true
    ```

2. Apply `vcluster.yaml`.
      <DeployChanges/>

### Sync ingress from virtual to host

Create an ingress in a virtual cluster to make a service in that virtual cluster available via a hostname/domain. Instead of having to run a separate ingress controller in each virtual cluster, sync the ingress resource to the host cluster so that the virtual cluster can use a shared ingress controller running in the host cluster.

1. Modify `vcluster.yaml`.

    ```yaml
    sync:
      toHost:
        ingresses:
          enabled: true
    ```

2. Apply `vcluster.yaml`.
      <DeployChanges/>

### Sync services from host to virtual cluster

In this example, you map a service `my-host-service` in the namespace `my-host-namespace` to the virtual cluster service `my-virtual-service` inside the virtual cluster namespace `team-x`.

1. Modify `vcluster.yaml`.

   ```yaml
   replicateServices:
     fromHost:
     - from: my-host-namespace/my-host-service
       to: team-x/my-virtual-service
   ```

1. Apply `vcluster.yaml`.
   
   <DeployChanges/>


## Delete vCluster

<Cleanup/>

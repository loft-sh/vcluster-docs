---
title: StatefulSet
sidebar_label: statefulSet
sidebar_position: 3
sidebar_class_name: host-nodes private-nodes
---

import ControlPlaneStatefulSet from '../../../../_partials/config/controlPlane/statefulSet.mdx'
import TenancySupport from '../../../../_fragments/tenancy-support.mdx';

<TenancySupport hostNodes="true" privateNodes="true" />

The vCluster control plane typically runs as a `StatefulSet` to ensure data persists across restarts. This setup uses a `PersistentVolume` for state storage. However, if you set `statefulSet.persistence.volumeClaim.enabled: false` or omit the `statefulSet.persistence.volumeClaimTemplates` configuration, vCluster defaults to deploying the control plane as a `Deployment`, which does not retain state across restarts.

## Configure high availability

Use the `highAvailability` settings to run multiple replicas of the vCluster control plane. One pod acts as the leader, while the others remain on standby:

- If the leader pod crashes, becomes unhealthy, or restarts, another pod automatically takes over leadership.

- The number of available replicas determines how quickly a new leader can be elected.

- You can fine-tune the leader election process using the following settings:
  - `leaseDuration`: Maximum time a leader can hold leadership without renewal.
  - `renewDeadline`: Time a pod waits to renew its leadership before it gives up.
  - `retryPeriod`: Interval between retries when attempting to acquire or renew leadership.

## Schedule virtual cluster pods

You can configure how and where virtual cluster pods are scheduled within the Kubernetes cluster. Configure the scheduling field with the following options to control pod placement in the cluster:

- **`nodeSelector`**  
  Match specific node labels to guide the scheduler toward preferred nodes. Examples include:  
  - Targeting nodes in a specific region  
  - Selecting nodes with a specific architecture or machine class

- **`affinity`** 
  Set rules to control how pods are scheduled in relation to other pods.  
  - Use anti-affinity (repel the pod) to keep virtual cluster pods on separate nodes. A common technique is to make virtual cluster pods repel each other so that they are not scheduled on the same nodes.This increases resiliency if a node is scaled down or replaced.  
  - Use affinity (attract the pod) to group related pods together and reduce network latency for critical services.

- **`tolerations`**  
  Allow pods to run on nodes with specific taints. Use this to schedule virtual cluster pods on nodes that would otherwise reject them. A common pattern is to taint nodes for non-virtual-cluster workloads and configure virtual cluster pods to tolerate the taint. This keeps virtual clusters separate from critical workloads. See [Taints and Tolerations](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/) for more information.

- **`priorityClassName`**  
  Set the podâ€™s priority to control scheduling order and preemption. See the [Pod Priority and Preemption](https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/) documentation for details.

- **`podManagementPolicy`**
  Control how StatefulSets create and delete pods. See [Pod Management Policies](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies) for details.

- **`topologySpreadConstraints`**
  Spread pods evenly across zones, nodes, or other topology domains. See [Pod Topology Spread Constraints](https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/) and the [comparison with `podAffinity` and `podAntiAffinity`](https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/#comparison-with-podaffinity-podantiaffinity) for more information.

<!-- vale off -->
## Reuse an existing PersistenceVolumeClaim
<!-- vale on -->

You can pre-provision a `PersistenceVolumeClaim`, and then configure vCluster to use it.

To do this, set the existing claim name in the chart values `controlPlane.statefulSet.persistence.dataVolume` under `persistenceVolumeClaim.claimName`:

```yaml
controlPlane:
  statefulSet:
    persistence:
      dataVolume:
        - name: data
          persistentVolumeClaim:
            claimName: my-existing-pvc
```

## vCluster image options

There are currently 3 vCluster image builds you can use in `statefulSet.image.repository`: 

- `loft-sh/vcluster-pro`: The default image for the Helm chart. This image works for all use cases.
- `loft-sh/vcluster-oss`: An open source build of vCluster
- `loft-sh/vcluster`: Deprecated. Use `loft-sh/vcluster-oss` instead.

## Config reference

<ControlPlaneStatefulSet/>

---
title: Embedded etcd
sidebar_label: embedded
sidebar_position: 2
sidebar_class_name: pro
description: Configure an embedded etcd instance as the virtual cluster's backing store.
---

import ConfigReference from '../../../../../../_partials/config/controlPlane/backingStore/etcd/embedded.mdx'
import ProAdmonition from '../../../../../../_partials/admonitions/pro-admonition.mdx'
import BackingStoreMigration from '../../../../../../_partials/config/controlPlane/backingStore/backing-store-migration.mdx'
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

<ProAdmonition/>

When using this backing store option, etcd is deployed as part of the vCluster control plane pod to reduce the overall footprint.

<BackingStoreMigration/>

```yaml
controlPlane:
  backingStore:
    etcd:
      embedded:
        enabled: true
```

## How embedded etcd works

Embedded etcd starts the etcd binary with the Kubernetes control plane inside the vCluster pod. This enables vCluster to run in high availability (HA) scenarios without requiring a separate `StatefulSet` or `Deployment`.

vCluster fully manages embedded etcd and provides these capabilities:

- **Dynamic scaling**: Scales the etcd cluster up or down based on vCluster replica count.
- **Automatic recovery**: Recovers etcd in failure scenarios such as corrupted members.
- **Seamless migration**: Migrates from SQLite or deployed etcd to embedded etcd automatically.
- **Simplified deployment**: Requires no additional `StatefulSets` or `Deployments`.

<!-- vale off -->
## Scaling behavior

vCluster dynamically builds the etcd cluster based on the number of desired replicas. For example, when you scale vCluster from 1 to 3 replicas, vCluster automatically adds the new replicas as members to the existing single-member cluster. Similarly, vCluster removes etcd members when you scale down the cluster.

When scaling down breaks quorum (such as scaling from 3 to 1 replicas), vCluster rebuilds the etcd cluster without data loss or interruption. This enables dynamic scaling up and down of vCluster.

## Disaster recovery

When embedded etcd encounters failures, vCluster provides both automatic and manual recovery options to restore cluster capabilities.

### Automatic recovery

vCluster recovers the etcd cluster automatically in most failure scenarios by removing and readding the failing member. Automatic recovery occurs in these cases:

- **Unresponsive member**: Etcd member is unresponsive for more than 2 minutes.
- **Detected issues**: Corruption or another alarm is detected on the etcd member.

vCluster attempts to recover only a single replica at a time. If recovering an etcd member results in quorum loss, vCluster does not recover the member automatically.

### Manual recovery

#### Recover a single replica

When a single etcd replica fails, vCluster can recover the replica automatically in most cases, including:

- Replica database corruption
- Replica database deletion
- Replica PVC deletion
- Replica removal from etcd cluster using `etcdctl member remove ID`
- Replica stuck as a learner

If vCluster cannot recover the single replica automatically, wait at least 10 minutes before deleting the replica pod and PVC. This action causes vCluster to rejoin the etcd member.

#### Recover the entire cluster

In rare cases, the entire etcd cluster requires manual recovery. This occurs when the majority of etcd member replicas become corrupted or deleted simultaneously (such as 2 of 3, 3 of 5, or 4 of 7 replicas). In this scenario, etcd fails to start and vCluster cannot recover automatically.

:::note
Normal pod restarts or terminations do not require manual recovery. These events trigger automatic leader election within the etcd cluster.
:::

Recovery procedures depend on whether the first replica (the pod ending with `-0`) is among the failing replicas:

<Tabs>
<TabItem value="first-replica-working" label="First replica is not failing">

<Flow>
<Step title="Scale down the vCluster StatefulSet to a single replica">
Scale the StatefulSet to one replica:

```bash
kubectl scale statefulset <vcluster-name> --replicas=1 -n <namespace>
```

- Replace `<vcluster-name>` with your actual vCluster StatefulSet name
- Replace `<namespace>` with your actual namespace name

Verify only one pod is running:

```bash
kubectl get pods -l <vcluster-label> -n <namespace>
```

- Replace `<vcluster-label>` with your actual vCluster pod label (for example `app=vcluster`)
- Replace `<namespace>` with your actual namespace name
</Step>

<Step title="Monitor the etcd cluster rebuild">
Monitor the rebuild process:

```bash
kubectl logs -f <vcluster-name>-0 -n <namespace>
```

- Replace `<vcluster-name>` with your actual vCluster StatefulSet name
- Replace `<namespace>` with your actual namespace name

Watch for log messages indicating etcd is ready and the cluster is healthy.
</Step>

<Step title="Scale up to the desired number of replicas">
Scale back up to your target replica count:

```bash
kubectl scale statefulset <vcluster-name> --replicas=<desired-replica-count> -n <namespace>
```

- Replace `<vcluster-name>` with your actual vCluster StatefulSet name
- Replace `<desired-replica-count>` with your target number (for example `3`)
- Replace `<namespace>` with your actual namespace name

Verify all replicas are running:

```bash
kubectl get pods -l <vcluster-label> -n <namespace>
kubectl logs <vcluster-name>-0 -n <namespace> | grep "cluster is ready"
```

- Replace `<vcluster-label>` with your actual vCluster pod label (for example `app=vcluster`)
- Replace `<namespace>` with your actual namespace name
- Replace `<vcluster-name>` with your actual vCluster StatefulSet name
</Step>
</Flow>

</TabItem>

<TabItem value="first-replica-failing" label="First replica is failing">

<Flow>
<Step title="Scale down vCluster to 0 replicas">
Stop all vCluster instances:

```bash
kubectl scale statefulset <vcluster-name> --replicas=0 -n <namespace>
```

- Replace `<vcluster-name>` with your actual vCluster StatefulSet name
- Replace `<namespace>` with your actual namespace name

Confirm all pods have terminated:

```bash
kubectl get pods -l <vcluster-label> -n <namespace>
```

- Replace `<vcluster-label>` with your actual vCluster pod label (for example `app=vcluster`)
- Replace `<namespace>` with your actual namespace name
</Step>

<Step title="Delete the PersistentVolumeClaim of the first replica">
Delete the corrupted PVC for the first replica:

```bash
kubectl delete pvc <pvc-prefix>-<vcluster-name>-0 -n <namespace>
```

- Replace `<pvc-prefix>` with your actual PVC prefix (commonly `data`)
- Replace `<vcluster-name>` with your actual vCluster StatefulSet name
- Replace `<namespace>` with your actual namespace name

Verify the PVC has been deleted:

```bash
kubectl get pvc -l <vcluster-label> -n <namespace>
```

- Replace `<vcluster-label>` with your actual vCluster pod label (for example `app=vcluster`)
- Replace `<namespace>` with your actual namespace name
</Step>

<Step title="Copy the PersistentVolumeClaim from a working replica">
Create a new PVC by [copying from a working replica](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#volume-cloning):

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: <pvc-prefix>-<vcluster-name>-0
  namespace: <namespace>
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: <storage-size>
  dataSource:
    name: <pvc-prefix>-<vcluster-name>-1
    kind: PersistentVolumeClaim
  storageClassName: <storage-class>
```

- Replace `<pvc-prefix>-<vcluster-name>-0` with your actual target PVC name (for example `data-my-vcluster-0`)
- Replace `<namespace>` with your actual namespace name
- Replace `<storage-size>` with your actual storage size (for example `5Gi`)
- Replace `<pvc-prefix>-<vcluster-name>-1` with your actual source PVC name (for example `data-my-vcluster-1`)
- Replace `<storage-class>` with your actual storage class name (for example `gp2`)

Apply the PVC:

```bash
kubectl apply -f <pvc-restore-file>.yaml
```

- Replace `<pvc-restore-file>` with your actual YAML filename (for example `restore-pvc.yaml`)
</Step>

<Step title="Scale up vCluster to a single replica">
Start with one replica to verify the restored data:

```bash
kubectl scale statefulset <vcluster-name> --replicas=1 -n <namespace>
```

- Replace `<vcluster-name>` with your actual vCluster StatefulSet name
- Replace `<namespace>` with your actual namespace name

Monitor the startup:

```bash
kubectl logs -f <vcluster-name>-0 -n <namespace>
```

- Replace `<vcluster-name>` with your actual vCluster StatefulSet name
- Replace `<namespace>` with your actual namespace name

After it's stable, scale up to the desired number of replicas.
</Step>
</Flow>

</TabItem>

<TabItem value="complete-data-loss" label="Complete data loss scenario">

<Flow>
<Step title="Assess the damage" danger>
Verify all PVCs are corrupted or inaccessible:

:::warning
This recovery method results in data loss up to the last backup point.
:::

```bash
kubectl get pvc -l <vcluster-label> -n <namespace>
```

- Replace `<vcluster-label>` with your actual vCluster pod label (for example `app=vcluster`).
- Replace `<namespace>` with your actual namespace name.

```bash
kubectl describe pvc <pvc-prefix>-<vcluster-name>-0 <pvc-prefix>-<vcluster-name>-1 <pvc-prefix>-<vcluster-name>-2 -n <namespace>
```

- Replace `<pvc-prefix>` with your actual PVC prefix (commonly `data`)
- Replace `<vcluster-name>` with your actual vCluster StatefulSet name
- Replace `<namespace>` with your actual namespace name
</Step>

<Step title="Scale down to zero replicas">
Stop all vCluster instances before beginning recovery:

```bash
kubectl scale statefulset <vcluster-name> --replicas=0 -n <namespace>
```

- Replace `<vcluster-name>` with your actual vCluster StatefulSet name
- Replace `<namespace>` with your actual namespace name
</Step>

<Step title="Restore from backup or snapshot">
Follow your backup restoration procedure. This typically involves:

1. Delete all existing corrupted PVCs
2. Restore PVCs from your backup solution (Velero, CSI snapshots, etc.)
3. Ensure the restored PVCs have the correct names and labels

Delete corrupted PVCs:

```bash
kubectl delete pvc <pvc-prefix>-<vcluster-name>-0 <pvc-prefix>-<vcluster-name>-1 <pvc-prefix>-<vcluster-name>-2 -n <namespace>
```

- Replace `<pvc-prefix>` with your actual PVC prefix (commonly `data`)
- Replace `<vcluster-name>` with your actual vCluster StatefulSet name
- Replace `<namespace>` with your actual namespace name

Restore from snapshot:

```bash
kubectl apply -f <backup-restore-file>.yaml
```

- Replace `<backup-restore-file>` with your actual backup restoration filename (for example `backup-restore.yaml`)
</Step>

<Step title="Start vCluster with restored data">
Scale up to a single replica to verify the restoration:

```bash
kubectl scale statefulset <vcluster-name> --replicas=1 -n <namespace>
```

- Replace `<vcluster-name>` with your actual vCluster StatefulSet name
- Replace `<namespace>` with your actual namespace name

Monitor logs and verify the cluster starts successfully:

```bash
kubectl logs -f <vcluster-name>-0 -n <namespace>
```

- Replace `<vcluster-name>` with your actual vCluster StatefulSet name
- Replace `<namespace>` with your actual namespace name

After it is verified, scale to the desired number of replicas.
</Step>
</Flow>

</TabItem>
</Tabs>

## Config reference

<ConfigReference/>

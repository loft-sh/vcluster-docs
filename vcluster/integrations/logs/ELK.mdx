---
title: Elastic Stack
sidebar_label: Elastic Stack
sidebar_position: 2
description: Learn how to deploy a sample ELK stack with Kind
---
import BasePrerequisites from '../../../platform/_partials/install/base-prerequisites.mdx';




### Prerequisites
Before starting, ensure you have the following tools installed:

<BasePrerequisites />


### Add the Helm repo and install a single-node  ELK instance. 

You can find the charts for the ELK(elasticsearch,kibana and logstash) in this public [repo](https://github.com/kirillyesikov/ELK_helm_4_vCluster).


```bash title="Elasticsearch and Kibana charts"
helm repo add ELK_4_vCluster https://kirillyesikov.github.io/ELK_helm_4_vCluster/
helm upgrade --install elastic ELK_4_vCluster/elasticsearch  -n logging --create-namespace --set replicas=1
helm upgrade --install kibana ELK_4_vCluster/kibana  -n logging  --set replicas=1
```


### Install  logstash

:::caution
Make sure you change the password for the logstashPipeline and logstashConfig in the `values.yaml`.
:::

1.  Change the password for the logstash Helm chart `values.yaml`.
     * To obtain the password you need to decode it from the secret: `kubectl get secrets -n logging elasticsearch-master-credentials -o jsonpath='{.data.password}' | base64 -D`.
     * Pull the helm chart locally `helm pull ELK_4_vCluster/logstash --untar`.
     * Change the password for the logstashPipeline and logstashConfig in the `*/logstash/values.yaml` manually.

```bash title="values.yaml"
logstashConfig: 
  logstash.yml: |
    http.host: 0.0.0.0
    xpack.monitoring.enabled: true
    xpack.monitoring.elasticsearch.hosts: [https://elasticsearch-master:9200]
    xpack.monitoring.elasticsearch.username: elastic
    xpack.monitoring.elasticsearch.password: "t7BkKsbJOQM0oH7n"
    xpack.monitoring.elasticsearch.ssl.certificate_authority: /usr/share/elasticsearch/config/certs/ca.crt
logstashPipeline: 
  logstash.conf: |
    input {
      http {
        port => 8080
      }
    }
    output {
      elasticsearch {
        hosts => [https://elasticsearch-master:9200]
        user => elastic
        password => "t7BkKsbJOQM0oH7n"
        cacert => /usr/share/elasticsearch/config/certs/ca.crt
      }
    }   
```
:::info
This logstashPipeline config creates an `ecs-logstash` template that is pushed to elasticsearch.
:::

After the change, install the helm chart itself using the edited `values.yaml`.

```bash
helm upgrade --install logstash ELK_4_vCluster/logstash -f ./values.yaml  -n logging --set replicas=1
```




### Install fluentd imperatively using the daemonset  
You can download the deamonset from [github](https://github.com/kirillyesikov/ELK_helm_4_vCluster/blob/main/fluentd-daemonset-elasticsearch-rbac.yaml):

```bash
kubectl apply -f fluentd-daemonset-elasticsearch-rbac.yaml
```
Alternatively, you can also deploy via the [helm charts provided by fluentbit](https://docs.fluentbit.io/manual/installation/kubernetes#installing-with-helm-chart).


### Setup ELK indexes  
1. Open the Kibana Dashboard:
     * Port-forward kibana dashboard on its default port `kubectl port-forward -n logging svc/kibana-kibana 5601`
     * Get Kibana credentials: `kubectl get secrets -n logging elasticsearch-master-credentials -o jsonpath='{.data.password}' | base64 -D`
     * Navigate to [http://localhost:5601](http://localhost:5601)




 1.  Refer to this Kibana [tutorial](https://www.elastic.co/guide/en/elasticsearch/reference/8.5/index-mgmt.html) to setup some basic indices:
       * An `ecs-logstash` index template will allow you to create indices in the Kibana.
       * You can port-forward `kubectl port-forward -n logging svc/elasticsearch-master 9200` and view the indices created at [https://localhost:9200/_cat/indices](https://localhost:9200/_cat/indices).
   
 


  

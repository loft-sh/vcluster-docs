---
title: Deploy on EKS
sidebar_label: EKS
sidebar_position: 1
id: eks
description: Learn how to deploy vCluster on Amazon EKS, including storage provisioning with EBS CSI driver and IAM role configuration.
sidebar_class_name: host-nodes private-nodes 
---

import Mark from "@site/src/components/Mark";
import InterpolatedCodeBlock from "@site/src/components/InterpolatedCodeBlock";
import ProAdmonition from '../../../../_partials/admonitions/pro-admonition.mdx';
import InstallCli from '../../../../_partials/deploy/install-cli.mdx';
import KubeconfigUpdate from '@site/docs/_partials/kubeconfig_update.mdx';

import ControlPlaneOptions from '../../../../_fragments/deploy/nested/control-plane.mdx'
import WorkerNodeOptions from '../../../../_fragments/deploy/nested/worker-nodes.mdx'
import Deploy from '../../../../_partials/deploy/deploy.mdx'

<!-- vale off -->
# Deploy vCluster on EKS
<!-- vale on -->

This guide provides step-by-step instructions for deploying vCluster
on [Amazon EKS](https://aws.amazon.com/.).

## Prerequisites

Before staring, ensure you have the following tools installed:

- `kubectl` installed: Kubernetes command-line tool for interacting with the cluster. See [Install and Set Up kubectl](https://kubernetes.io/docs/tasks/tools/#kubectl) for installation instructions.
- `vCluster CLI` <InstallCli />
- [AWS CLI](https://aws.amazon.com/cli/) version <Mark color="lightgreen">1.16.156</Mark> or greater
  :::note
  AWS IAM permissions to create roles and policies
  :::
- [eksctl](https://eksctl.io/) installed for cluster management
  :::note
  [Upgrade](https://github.com/eksctl-io/eksctl?tab=readme-ov-file#installation) `eksctl` to the latest version to ensure latest Kubernetes version is
  deployed.
  :::

<!-- vale off -->
## Create EKS cluster
<!-- vale on -->

Start by creating EKS cluster using `eksctl`. This command creates a file named
`cluster.yaml` with the required settings. Adjust the cluster name, region, and instance type as needed.

<!-- vale off -->
<InterpolatedCodeBlock
  code={'# This will create a file with your custom values\n' +
'cat << EOF > cluster.yaml\n' +
'apiVersion: eksctl.io/v1alpha5\n' +
'kind: ClusterConfig\n' +
'metadata:\n' +
'  name: [[VAR:CLUSTER_NAME:vcluster-demo]]\n' +
'  region: [[VAR:REGION:eu-central-1]]\n' +
'iam:\n' +
'  withOIDC: true\n' +
'nodeGroups:\n' +
'  - name: ng-1\n' +
'    instanceType: [[VAR:INSTANCE_TYPE:t3.medium]]\n' +
'    desiredCapacity: 2\n' +
'    iam:\n' +
'      withAddonPolicies:\n' +
'        ebs: true\n' +
'    volumeSize: 80\n' +
'\n' +
'addons:\n' +
'  - name: aws-ebs-csi-driver\n' +
'    version: latest\n' +
'    attachPolicyARNs:\n' +
'      - arn:aws:iam::aws:policy/service-role/AmazonEBSCSIDriverPolicy\n' +
'EOF'}
  language="bash"
/>
<!-- vale on -->

The file defines a cluster with two `t3.medium` instances located in the `eu-central-1` region. The configuration includes:
- OIDC provider enabled for IAM roles for service accounts
- Node group with EBS addon policy for volume management
- EBS CSI driver addon with the official AWS managed IAM policy

Create the cluster by running:

```bash title="Create EKS cluster"
eksctl create cluster -f cluster.yaml
```

<KubeconfigUpdate />

This process typically takes about 15-20 minutes.

### Verify the host cluster creation

Verify the installation by checking if the CSI driver pods are running:

```bash title="Verify CSI driver installation"
kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-ebs-csi-driver
```

Expected output should look similar to:
```
NAME                                 READY   STATUS    RESTARTS   AGE
ebs-csi-controller-794b4448b-fhjxr   6/6     Running   0          2m14s
ebs-csi-controller-794b4448b-j94g5   6/6     Running   0          2m14s
ebs-csi-node-crz7p                   3/3     Running   0          2m14s
ebs-csi-node-jg8n8                   3/3     Running   0          2m14s
```

### Configure storage class

`vCluster` requires a default StorageClass for its persistent volumes. EKS provides the `gp2` StorageClass by default, but `gp3` is required. Create a new StorageClass:

```bash title="gp3 StorageClass configuration"
cat <<EOF | kubectl apply -f -
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: gp3
  annotations:
    storageclass.kubernetes.io/is-default-class: "true"
provisioner: ebs.csi.aws.com
parameters:
  type: gp3
  encrypted: "true"
volumeBindingMode: WaitForFirstConsumer
allowVolumeExpansion: true
EOF
```

Remove the default status from the `gp2` StorageClass:

```bash title="Remove default status from gp2 StorageClass"
kubectl patch storageclass gp2 -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"false"}}}'
```

## Predeployment configuration options

Before deploying, it's recommended to review the set of configuration options that cannot be updated post deployment. These options require deploying a new vCluster instead of upgrading your vCluster with new options.

<ControlPlaneOptions />
<WorkerNodeOptions />

## Deploy vCluster on EKS

:::tip YAML configuration
If you're not sure which options to configure, you can update most settings later by upgrading your vCluster with an updated `vcluster.yaml`.
However, some settings — such as what type of worker nodes or the backing store — can only be set during the initial deployment and cannot be changed during an upgrade.
:::

<Deploy />

This configuration ensures that:
- Service accounts are properly synced between virtual and host clusters
- Persistent volume claims are handled correctly
- The `gp3` storage class created earlier is used

### Allow internal DNS resolution

By default, vCluster runs a CoreDNS component inside the virtual cluster. This component listens on port `1053` instead of the standard DNS port `53` to avoid conflicts with the host cluster DNS.

On EKS, if the CoreDNS pod and other virtual cluster pods are scheduled on different nodes, DNS resolution may fail. This happens because AWS creates separate security groups for the EKS control plane and worker nodes, and the default node security group does not allow inbound traffic on port `1053`.

To resolve this, manually update the EKS node security group to allow inbound TCP and UDP traffic on port `1053` between nodes.

:::tip
This step is especially important for EKS clusters created using Terraform or other automation tools that apply restrictive network settings by default.
:::

## Next steps

Now that you have vCluster running on EKS, consider:

- Setting up the [platform UI](/platform/install/quick-start-guide) to mange your virtual clusters.
- Integrating with [Karpenter](/platform/integrations/karpenter) for autoscaling.

### Pod identity

<ProAdmonition />

When using the platform you can easily enable [Pod Identity](../../../../third-party-integrations/pod-identity/eks-pod-identity).

## Cleanup

If you deployed the EKS cluster with this tutorial, and want to clean up the resources, run the
following command:

```bash title="Clean up resources"
eksctl delete cluster -f cluster.yaml --disable-nodegroup-eviction
```

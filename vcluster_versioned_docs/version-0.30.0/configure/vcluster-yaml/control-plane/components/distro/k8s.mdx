---
title: Kubernetes distribution
sidebar_label: K8s
sidebar_position: 1
description: Configure Kubernetes as the distro for the virtual cluster.
sidebar_class_name: host-nodes private-nodes standalone
---

import DistroK8s from '../../../../../_partials/config/controlPlane/distro/k8s.mdx'
import K8sCompat from '../../../../../_fragments/distro/compat-k8s.mdx'
import DefaultDistroNote from '../../../../../_fragments/default-distro-note.mdx'

import TenancySupport from '../../../../../_fragments/tenancy-support.mdx';

<DefaultDistroNote/>

<TenancySupport hostNodes="true" privateNodes="true" standalone="true"/>

By default, <GlossaryTerm term="vcluster">vCluster</GlossaryTerm> uses an embedded SQLite as the [backing store](../backing-store/README.mdx) when you use the <GlossaryTerm term="k8s">K8s</GlossaryTerm> distribution.

:::warning
After deploying your vCluster, there are limited migration paths to change your backing store. Review the backing store migration options before deploying.
:::

## Compatibility matrix

<K8sCompat/>

## Configure Kubernetes version and image options {#setting-kubernetes-version}

When using the K8s distribution, you can configure the container image for the Kubernetes components. The K8s distribution deploys the <GlossaryTerm term="api-server">API server</GlossaryTerm>, controller manager, and scheduler as a single container from the [loft-sh/kubernetes](https://github.com/loft-sh/kubernetes) repository.

You can customize the container image by specifying the registry, repository, and tag in your vCluster configuration:

```yaml title="vcluster.yaml"
controlPlane:
  distro:
    k8s:
      image:
        registry: ghcr.io           # Default: ghcr.io (can be overridden globally with controlPlane.advanced.defaultImageRegistry)
        repository: loft-sh/kubernetes  # Default: loft-sh/kubernetes
        tag: v1.32.1                # Default: v1.32.1 (or matches host Kubernetes version)
```

The `tag` field specifies the Kubernetes version to use. By default, it uses v1.32.1 or matches the <GlossaryTerm term="host-cluster">host cluster</GlossaryTerm>'s Kubernetes version.

:::note
The `controlPlane.distro.k8s.version` field is deprecated. Use `controlPlane.distro.k8s.image.tag` instead to specify the Kubernetes version.
:::

## Configure API server rate limiting {#api-server-rate-limiting}

You can configure rate limiting for the vCluster API server to control the maximum number of requests it handles. This helps prevent the <GlossaryTerm term="virtual-cluster">virtual cluster</GlossaryTerm> from being overwhelmed and ensures stable performance under high load.

Use the `extraArgs` field to pass rate limiting flags to the API server:

```yaml title="vcluster.yaml"
controlPlane:
  distro:
    k8s:
      apiServer:
        extraArgs:
          - --max-requests-inflight=300
          - --max-mutating-requests-inflight=100
```

### Rate limiting options {#rate-limiting-options}

The [Kubernetes API server](https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/) supports these rate limiting flags:

- `--max-requests-inflight`: Maximum number of non-mutating requests (GET, LIST) that can be served at the same time. Default is 400.
- `--max-mutating-requests-inflight`: Maximum number of mutating requests (POST, PUT, PATCH, DELETE) that can be served at the same time. Default is 200.

:::note Impact on host cluster requests
The `--max-requests-inflight` and `--max-mutating-requests-inflight` flags only indirectly affect the number of requests sent to the host cluster. With the exception of Service creation, vCluster handles all resource creation asynchronously through the syncer, which self-throttles at a default rate of 40 QPS.
:::

:::info API Priority and Fairness
Starting with Kubernetes 1.20, the [API Priority and Fairness](https://kubernetes.io/docs/concepts/cluster-administration/flow-control/) feature changes how these limits work. When enabled, the total concurrency limit becomes the sum of both flags, and requests are distributed across configurable priority levels.
:::

### Choose appropriate values {#choosing-values}

When setting rate limits, consider:

- **Workload patterns**: Higher limits for read-heavy workloads, balanced limits for mixed workloads
- **Available resources**: Ensure the host cluster has sufficient CPU and memory to handle the configured limits
- **Client behavior**: Applications with many concurrent API calls may need higher limits
- **Platform limits**: Some managed Kubernetes platforms (like [EKS](https://docs.aws.amazon.com/eks/latest/best-practices/scale-control-plane.html)) may scale these values automatically

:::tip
Start with conservative values and monitor the API server's performance. Increase limits gradually based on actual usage patterns and available resources. Consider implementing [resource quotas](../../../policies/resource-quota.mdx) and [CPU/memory limits](../../../../../learn-how-to/control-plane/container/configure-memory-limits.mdx) alongside rate limiting for comprehensive resource management. You can also configure [admission control policies](../../../policies/admission-control.mdx) to further control resource usage.
:::

## Config reference

<DistroK8s/>
import ProAdmonition from '../../_partials/admonitions/pro-admonition.mdx'

<ProAdmonition/>

The Netris integration enables vCluster to use [Netris](https://www.netris.io/) for network automation for the vCluster control plane and [private nodes](../../deploy/worker-nodes/private-nodes/README.mdx).

## Features

For more information on the features capable of integrating with Netris, see:
- [Automatically configure kube-vip](#automatically-configure-kube-vip)
- [BCM Node Provider with Netris](/platform/administer/node-providers/bcm)
- [KubeVirt Node Provider with Netris](/platform/administer/node-providers/kubevirt)

## Configure Netris integration

1. Create a Secret in the host cluster in the namespace where vCluster Platform is installed to provide authentication and endpoint information:

    ```yaml
    apiVersion: v1
    kind: Secret
    metadata:
      name: netris-credentials
      namespace: vcluster-platform
    stringData:
      url: "https://netris.example.com/api"
      username: "admin"
      password: "password"
    ```

2. Reference the Secret in your `vcluster.yaml`:

    ```yaml
    integrations:
      netris:
        enabled: true
        connector: netris-credentials
    ```

## Automatically configure kube-vip

:::info
This requires [Multus](https://github.com/k8snetworkplumbingwg/multus-cni) to be installed in the host cluster.
:::

When the Netris integration is enabled, you can configure it to automatically configure kube-vip for your vCluster control plane.
The platform looks up the server cluster in Netris and uses the information to create the necessary Multus NetworkAttachmentDefinition and configure kube-vip.

Add the `kubeVip` configuration to your Netris integration:

```yaml
integrations:
  netris:
    enabled: true
    connector: netris-credentials
    kubeVip:
      # Netris server cluster to use for VIP allocation
      serverCluster: vcluster-control-plane
      # Optional: IP ranges to use for allocation instead of CIDR-based allocation
      ipRange: "10.0.0.10-10.0.0.20"
```

### How it works

When configured, vCluster Platform will:
1. Query the specified Netris server cluster to get subnet, gateway & vxlan id information
2. Allocate a VIP from the subnet (or from the specified IP range if `ipRange` is set)
3. Create a NetworkAttachmentDefinition with the specified bridge
4. Transparently configure kube-vip for the vCluster instance to announce the VIP

You don't need to configure any of this yourself.
The equivalent manual configuration would look like this:

```yaml
# transparently configured
controlPlane:
  # Set the endpoint to the allocated VIP
  endpoint: 10.0.0.11:8443
  statefulSet:
    annotations:
      # Reference the auto-created NetworkAttachmentDefinition
      k8s.v1.cni.cncf.io/networks: netris-kubevip-<vcluster-name>
  advanced:
    kubeVip:
      # enable kube-vip
      enabled: true
      # set to Multus interface
      interface: net1
      # set gateway and subnet prefix for policy-based routing
      gateway: 10.0.0.1/24
```

For more information on manual kube-vip configuration, see [Kube-vip](/vcluster/configure/vcluster-yaml/control-plane/other/advanced/kube-vip).

## Additional resources

- [Netris website](https://www.netris.io/)

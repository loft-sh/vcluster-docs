---
title: Migrate the platform to a different cluster
sidebar_label: Migrate Clusters
sidebar_position: 1
description: Learn how to migrate vCluster platform from one Kubernetes cluster to another.
---

import Flow, { Step } from '@site/src/components/Flow'
import BasePrerequisites from '../../_partials/install/base-prerequisites.mdx';

This guide explains how to migrate the platform to a different Kubernetes cluster, which may be necessary during cluster decommissioning or cloud platform migration.

## When to migrate

Migrating a platform to a new Kubernetes cluster is necessary in certain cases, such as infrastructure upgrades, cluster decommissioning, or scaling needs. Migrate the platform in the following situations :

- The existing cluster is being decommissioned. The platform must move to a new cluster.

- The platform is migrating to a new cluster. The original cluster is going to be cleaned up.

- The platform is migrating to a new cluster. The original cluster is going to be remain connected.


### Migration considerations

:::warning
IMPORTANT: the platform must run on a dedicated Kubernetes cluster. It must have its own ingress and DNS record before migration. Ensure these conditions are met before proceeding.
:::

Review the following factors before migrating. These scenarios require a different migration approach.

- **Loft router configurations**
  If the platform uses the Loft router (`<something.loft.host>`), special DNS handling is required. The DNS records must be updated to reflect the new cluster. Failure to update DNS settings can cause routing issues and service downtime.

- **Automated deployment tools**
  If the platform is managed by an automated deployment tool such as `ArgoCD`, migration must be coordinated with GitOps workflows. Changes to cluster configuration must be reflected in the repository before deployment. Skipping this step can lead to drift between the declared and actual state of the platform.

- **Virtual cluster dependencies**
  If the platform has virtual cluster instances running on the same Kubernetes host cluster, these instances do not migrate automatically. They require a separate migration process after the platform has been moved. Migrating only the platform without considering virtual clusters can cause service disruptions and dependency issues.

- **Virtual cluster agent on the destination cluster**
  If the destination Kubernetes cluster has a virtual cluster agent, it must be decommissioned before migration. The agent can interfere with the new platform installation, potentially leading to scheduling conflicts and unexpected behavior.

Not addressing these considerations before migration can lead to DNS misconfigurations, deployment failures, and conflicts with existing workloads.

## Prerequisites

### Base prerequisites

<BasePrerequisites />

### Platform specific prerequisites

- Storage space for backup (approximately 1GB).
- Access to DNS management for the platform's domain
- Only one platform instance can exist per Kubernetes cluster. Do not install the platform twice in the same Kubernetes host cluster.
- The migration process requires 15-30 minutes of downtime. Communicate this downtime to end users.
- The source and destination installations must use the same platform version. Version changes during migration are not supported.

## Migration steps

<Flow id="migration procedure">

### Install the platform in the new cluster
<Step>
Configuration

- Use the Helm values from the original installation, making adjustments to values like `ingressClass` or `storageClass` as necessary
- If your project namespaces have the "loft-p-" prefix, set `projectNamespacePrefix: loft-p-` in your configuration
</Step>

<Step>
Installation

Install the platform in the new cluster following the [quick start guide](/platform/install/quick-start-guide).

:::info Avoid DNS conflicts
When using cloud-managed ingress, use a temporary hostname to prevent conflicts with the running platform instance.
:::
</Step>

### Prepare for migration

<Step>
Send downtime communication to end users
</Step>

<Step>
Optional: stop `ArgoCD` sync of any virtual clusters
</Step>

<Step>
[Perform a backup of the source platform](/platform/administer/backup-restore/backup-restore-platform)
</Step>

### Execute migration

<Step>
Scale down the source platform:

```bash title="Scale down the platform deployment"
kubectl scale deployment loft --replicas=0 -n vcluster-platform
```
</Step>

<Step>
[Restore the backup to the new installation](https://www.vcluster.com/docs/platform/administer/backup-restore/backup-restore-platform#restoring-vcluster-platform-from-backup)
</Step>

<Step>
Apply the license certificate to the new cluster:

  ```bash title="Apply license certificate"
  TARGET_NAMESPACE='vcluster-platform'
  CA_CERT=$(kubectl get secret loft-cert -n vcluster-platform -o jsonpath="{.data.ca\.crt}")
  TLS_CERT=$(kubectl get secret loft-cert -n vcluster-platform -o jsonpath="{.data.tls\.crt}")
  PRIVATE_KEY=$(kubectl get secret loft-cert -n vcluster-platform -o jsonpath="{.data.tls\.key}")

  cat <<EOF > loft-cert-clean.yaml
  apiVersion: v1
  kind: Secret
  metadata:
    name: loft-cert
    namespace: ${TARGET_NAMESPACE}
  type: kubernetes.io/tls
  data:
    ca.crt: ${CA_CERT}
    tls.crt: ${TLS_CERT}
    tls.key: ${PRIVATE_KEY}
  EOF
  ```

  ```bash title="Apply license certificate"
  kubectl scale deployment loft --replicas=0 -n vcluster-platform
  kubectl delete secret loft-cert -n ${TARGET_NAMESPACE} --ignore-not-found
  kubectl create -f loft-cert-clean.yaml
  ```

</Step>
<Step>
Update the hostname in the platform configuration as described in the [configuration guide](https://www.vcluster.com/docs/platform/configure/config#changing-the-lofthost-variable)
</Step>
<Step>
Update the DNS record to point to the new cluster if needed
</Step>
<Step>
If the original cluster is going to be used as a connected cluster: connect it to the new platform installation
</Step>

</Flow>

## Post-migration validation
<Flow id="post-migration validation">
<Step>
Log in to the platform UI and verify object presence:
   - Check for all expected projects
   - Verify user access and permissions
   - Confirm virtual cluster listings
</Step>
<Step>
Verify license status in the platform UI:
   - Navigate to Settings â†’ License
   - Confirm license is active and correct
</Step>
<Step>
Restart platform agents on connected clusters:

  ```bash title="Restart platform agents"
  kubectl rollout restart deployment loft -n vcluster-platform
  ```
</Step>
<Step>
Validate the core capabilities of the platform:
   - Single Sign-on: test login with all configured providers
   - Log access: verify log retrieval from multiple virtual clusters
   - Virtual cluster creation: create a test cluster
   - Sleep mode: test sleep/wake feature
</Step>
<Step>
Optional: restart `ArgoCD` sync if previously stopped
</Step>
<Step>
Send end-of-downtime communication to end users
</Step>
</Flow>

---
title: Deploy in Air-Gapped Environments
sidebar_label: Using Air-Gapped Installation
sidebar_position: 1
description: Learn how to install vCluster Platform in air-gapped, offline, or VPC environments with restricted network connectivity.
---

import Flow, { Step } from "@site/src/components/Flow";
import PartialAdminSetVersion from "../../_partials/install/set-version.mdx";
import PartialAdminUpgrade from "../../_partials/install/upgrade.mdx";
import Mark from "@site/src/components/Mark";

import BasePrerequisites from '../../_partials/install/base-prerequisites.mdx';

import LoginAfterHelmInstall from '../../_partials/install/login-after-helm-install.mdx';

import InstallNextSteps from '../../_partials/install/install-next-steps.mdx';


If your cluster is air-gapped, within a VPC, or has restricted network connectivity, you may encounter issues validating the platform license and pulling required container images.

To solve the licensing issue, you can either use allow HTTP requests from
the platform pods to
`https://admin.loft.sh/*` (this is the preferred option), or use an
[offline license key](#offline-license-key).

To address image pulling issues from Docker Hub, you can [use a private image
registry](#offline-images) to host your own copies of the platform images
accessible to your cluster.

## Prerequisites

<BasePrerequisites />

-  A private Docker registry accessible to both the installer computer and the air-gapped Kubernetes cluster
### Optional prerequisites

- On the installation computer:
  - `docker` (verify with `docker version`)
  - An offline license key for the platform (provided by Loft)

### Supported Kubernetes versions

- A running air-gapped Kubernetes cluster with one of the supported versions: `v1.30.x`, `v1.31.x`, or `v1.32.x`

:::note
Although the platform may work with other versions, using the supported versions is recommended to avoid potential issues.
:::

### Resource requirements

- Pod Resource Requirements:

  - Requests
    - memory: `256Mi`
    - cpu: `200m`
  - Limits
    - memory: `4Gi`
    - cpu: `2`

- Open network ports:
  :::info
  The platform installs webhooks and API server extensions into the cluster. The Kubernetes master needs to communicate with the platform pods. For example, in private GKE clusters, the Kubernetes master and nodes are not in the same subnetwork and cannot communicate directly on every port. Ensure a firewall rule allows incoming traffic from the Kubernetes master network to the following TCP ports:
  :::
  - `8443` (platform agent API service extension - `v1.cluster.loft.sh`)
  - `9443` (platform agent webhook & loft webhook)
  - `9444` (platform API service extension - `v1.management.loft.sh`)
  :::info
  The platform's cost control dashboard federates metrics from each connected cluster. In order to scrape these metrics, it utilizes the local cluster agent to proxy to the cluster's Prometheus pods. The agent requires connectivity over TCP port `9090` to access the Prometheus pods.
  :::
  - `9090` (cost control dashboard Prometheus pods)

## Deployment

### Offline Images

For clusters unable to pull images from Docker Hub, you need to push the platform images to your private registry. Each platform release includes a `loft-images.txt` file that lists the necessary images.

:::warning
When using virtual clusters in air-gapped environments, the
`config.experimental.deploy.vcluster.helm` [configuration setting](/docs/vcluster/configure/vcluster-yaml/#experimental-deploy-vcluster) does not work with external Helm repositories since they cannot be accessed. This means custom Helm charts from repositories like `charts.bitnami.com` cannot be used for virtual cluster deployments.
:::

Follow these instructions to download all platform images and import them to your private registry:

<Flow id="offline-images">
    <Step>
        <PartialAdminSetVersion/>
  </Step>
  <Step>

Set your private registry as a variable:

```bash title="Set private registry"
REGISTRY=ecr.io/myteam      # This should be a prefix; do not include any LOFT_IMAGE paths
```

  </Step>
  <Step>

Download the `loft-images.txt` file and the required scripts `download-images.sh` and `push-images.sh`, then make them executable:

```bash title="Download and prepare scripts"
wget https://github.com/loft-sh/loft/releases/download/v${VERSION}/loft-images.txt
wget https://github.com/loft-sh/loft/releases/download/v${VERSION}/download-images.sh
wget https://github.com/loft-sh/loft/releases/download/v${VERSION}/push-images.sh

chmod +x ./download-images.sh
chmod +x ./push-images.sh
```

  </Step>
  <Step>

Run `download-images.sh` to download all images locally:

```bash title="Download images"
./download-images.sh --image-list loft-images.txt
```

  </Step>
  <Step>

Run `push-images.sh` to push all downloaded images to your private registry:

```bash title="Push images to private registry"
./push-images.sh --registry ${REGISTRY}
```

    </Step>
    <Step>

Edit your existing `vcluster-platform.yaml` file or create a new one with the following content:

```yaml title="vcluster-platform.yaml"
image: ${REGISTRY}/ghcr.io/loft-sh/loft:${VERSION} # Replace ${REGISTRY} and ${VERSION}
env:
  DEFAULT_IMAGE_REGISTRY: ${REGISTRY} # Replace ${REGISTRY}
```

:::info Example of a fully formed registry path
If your `REGISTRY` is set to `ecr.io/myteam`, a fully formed registry path might look like:
`ecr.io/myteam/ghcr.io/loft-sh/loft:3.0.0`
:::

    </Step>
    <Step>
        <PartialAdminUpgrade/>
    </Step>

</Flow>


## Configuration

#### Offline license key

If your cluster does not allow the platform pod to connect to the platform license server (`https://admin.loft.sh/*`), contact [sales@loft.sh](mailto:sales@loft.sh) to purchase an offline license key or request a trial license key for offline use.

Edit the platform install values as follows to use your offline license key:

```yaml title="Offline license configuration"
env:
  LICENSE_KEY: "YOUR_LICENSE_KEY"
```

:::info
Apply this configuration during the initial installation process or when upgrading the platform. Include it in your `vcluster-platform.yaml` file or pass it as a value to the Helm install/upgrade command.
:::
## Login

<LoginAfterHelmInstall />

## Next steps
### Create virtual clusters
<InstallNextSteps />
